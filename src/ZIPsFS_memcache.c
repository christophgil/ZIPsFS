///////////////////////////////////////////////////////////////////////////
/// COMPILE_MAIN=ZIPsFS                                                 ///
/// In memory cache                                                     ///
/// Caching file data in main memory                                    ///
/// Usually applies to compressed ZIP entries and                       ///
/// autogenerated content and special files                             ///
///////////////////////////////////////////////////////////////////////////
#include "cg_crc32.c"
////////////////////////////////////
/// Parameters from command line ///
////////////////////////////////////
static bool memcache_set_maxbytes(const char *s){
  if ((_memcache_bytes_limit=cg_atol_kmgt(s))<(1<<22)){
    log_error("Option -l: _memcache_bytes_limit is too small %s\n",s);
    return false;
  }
  return true;
}
static bool memcache_set_policy(const char *a){
  bool ok=false;
  const char *s;
  for(int i=0;!ok && (s=rm_pfx_us(WHEN_MEMCACHE_S[i]));i++){
    if ((ok=!strcasecmp(s,a))) _memcache_policy=i;
  }
  if (!ok){ log_error("Wrong option -c %s\n",a); ZIPsFS_usage(); }
  return ok;
}
///////////////////////////////
/// Decide for cache in RAM ///
///////////////////////////////
static off_t ramUsageForFilecontent(void){
  LOCK_N(mutex_fhandle,const off_t u=textbuffer_memusage_get(0)+textbuffer_memusage_get(TEXTBUFFER_MEMUSAGE_MMAP));
  return u;
}
/* File info for virtual-path plus root-path Needed  when loading analysis.tdf, also wait for sufficient RAM  for analysis.tdf_bin */
static bool statForVirtualpathAndRootpath(struct stat *st, const char *vp, const char *rootpath){
  struct rootdata *r=NULL;
  foreach_root(r2) if (r2->rootpath==rootpath) r=r2;
  if (!r) return false;
  NEW_ZIPPATH(vp);
  //log_entered_function("%s r: %p",vp,r);
  const bool ok=find_realpath_for_root(zpath,r);
  *st=ok?zpath->stat_vp: empty_stat;
  //log_exited_function("%s found: %d  size: %ld ",vp,ok,st->st_size);
  return ok;
}

static bool advise_cache_in_ram(const struct zippath *zpath, const int additional_flags,const bool wait_for_free_mem){
  cg_thread_assert_not_locked(mutex_fhandle);
  if (_memcache_policy==MEMCACHE_NEVER) return false;
  const bool c=zpath->flags&ZP_IS_COMPRESSED, z=zpath->flags&ZP_ZIP;
  const off_t need_bytes=config_advise_cache_in_ram(additional_flags|
                                                    (c?ADVISE_CACHE_IS_CMPRESSED:0)|
                                                    (z?ADVISE_CACHE_IS_ZIPENTRY:0)|
                                                    ((_memcache_policy==MEMCACHE_COMPRESSED&&c || z&&_memcache_policy==MEMCACHE_ALWAYS)?ADVISE_CACHE_BY_POLICY:0),
                                                    VP(),VP_L(),RP(),RP_L(),zpath->root->rootpath,zpath->stat_vp.st_size);

  log_debug_now("VP: %s need_bytes: %lld",VP(),(LLD)need_bytes);
  if (need_bytes<0) return false;
  if (need_bytes>_memcache_bytes_limit){
    warning(WARN_MEMCACHE|WARN_FLAG_ONCE,VP(),"%'lld>%'lld. Consider set byte limit for RAM cache with  "ANSI_FG_BLUE"-l <gigabytes>G"ANSI_RESET,(LLD)need_bytes,(LLD)_memcache_bytes_limit);
    return false;
  }
  if (wait_for_free_mem){
    for(off_t u; (u=ramUsageForFilecontent()+need_bytes)>_memcache_bytes_limit;){
      log_verbose("Pause while high RAM usage:  %s usage+need >= max  (%'lld+%'lld >= %'lld \n",VP(),(LLD)u,(LLD)need_bytes,(LLD)_memcache_bytes_limit);
      usleep((1<<20));
    }
  }
  return true;
}

#define fhandle_advise_cache_in_ram(d) advise_cache_in_ram(&d->zpath,(d->flags&FHANDLE_FLAG_SEEK_BW_FAIL)?ADVISE_CACHE_IS_SEEK_BW:0,true)  /* Called from xmp_read() */
#define zpath_advise_cache_in_ram(zpath) advise_cache_in_ram(zpath,0,false) /* Called from xmp_open() */

//////////////
/// Status ///
//////////////
static enum enum_memcache_status memcache_get_status(const struct fHandle *d){
  ASSERT_LOCKED_FHANDLE();
  return d && d->memcache?d->memcache->memcache_status:memcache_status_nil;
}
static void memcache_set_status(struct fHandle *d,enum enum_memcache_status status){
  ASSERT_LOCKED_FHANDLE();
  if (d && d->memcache) d->memcache->memcache_status=status;
}
//////////////////////////////////
/// Constructor and Destructor ///
//////////////////////////////////
static struct memcache *memcache_new(struct fHandle *d){
  ASSERT_LOCKED_FHANDLE();
  if (!d->memcache){
    static int id;
    (d->memcache=cg_calloc(COUNT_MEMCACHE_MALLOC,1,sizeof(struct memcache)))->id=++id;
    d->memcache->memcache_l=d->zpath.stat_vp.st_size;
    d->memcache->m_zpath=d->zpath;

    foreach_fhandle(ie,e){
      if (fhandle_virtualpath_equals(d,e)){
        ASSERT(d->flags&FHANDLE_FLAG_SPECIAL_FILE || !e->memcache);
        e->memcache=d->memcache;
      }
    }
  }
  return d->memcache;
}
static bool memcache_try_destroy(struct fHandle *d){
  ASSERT_LOCKED_FHANDLE();
  struct memcache *m=d->memcache;
  if (m){
    if (is_memcache_shared_with_other(d)) return false;
    textbuffer_destroy(m->txtbuf);
    FREE_NULL_MALLOC_ID(m->txtbuf);
    cg_free_null(COUNT_MEMCACHE_MALLOC,d->memcache);
    foreach_fhandle_also_emty(id,e) if (e->memcache==m) e->memcache=NULL;
  }
  return true;
}
//////////////////////////////////////////////////////////////////////////////////////////
/// Instances of struct memcache are shared by multiple instances of struct fHandle,   ///
/// when a file is open multiple times in the client app.                              ///
//////////////////////////////////////////////////////////////////////////////////////////
static void memcache_infer_from_other_handle(struct fHandle *d){
  ASSERT_LOCKED_FHANDLE();
  foreach_fhandle(ie,e){
    if (e->memcache && fhandle_virtualpath_equals(d,e)){
      d->memcache=e->memcache;
      break;
    }
  }
}
static bool is_memcache_shared_with_other(const struct fHandle *d){
  ASSERT_LOCKED_FHANDLE();
  if (d->memcache){
    foreach_fhandle(id,e){
      if (e!=d && e->memcache==d->memcache && !(e->flags&FHANDLE_FLAG_DESTROY_LATER)){
        assert(fhandle_virtualpath_equals(d,e));
        return true;
      }
    }
  }
  return false;
}
////////////////////////////////////////////////////////////////////////
///  rootdata may change by find_realpath_other_root()               ///
///  Check that memcache is not NULL and that  root is still correct ///
////////////////////////////////////////////////////////////////////////
#define is_memcache(d,r) _is_memcache(d,r,__func__,__LINE__)
static bool _is_memcache(const struct fHandle *d, const struct rootdata *r,const char *func,const int line){
  ASSERT_LOCKED_FHANDLE();
  if (!d || !d->memcache || !d->memcache->txtbuf){
    log_verbose("%s:%d !memcache %s",func,line,d?D_VP(d):NULL);
    return false;
  }
  if (r && d->memcache->m_zpath.root!=r){
    log_verbose("%s:%d wrong root %s",func,line,D_VP(d));
    return false;
  }
  return true;
}
/* Check whether d and  d->memcache are not used by open file connections. */
static bool memcache_can_break(const struct fHandle *d){
  ASSERT_LOCKED_FHANDLE();
  return (d->flags&FHANDLE_FLAG_DESTROY_LATER) && !fhandle_currently_reading_writing(d)  && !is_memcache_shared_with_other(d);
}
////////////////////////////////////////////////////////////////////////////////
/// Reading the cached bytes from the RAM                                    ///
/// Called from memcache_wait_and_read(), fhandle_read_zip()  and xmp_read() ///
////////////////////////////////////////////////////////////////////////////////
static off_t memcache_read(char *buf,const struct fHandle *d,const off_t from,off_t to){
  ASSERT_LOCKED_FHANDLE();
  if (!d || !d->memcache || !d->memcache->txtbuf) return -1;
  to=MIN(to,d->memcache->memcache_already);
  if (to==from) return 0; /* Note that returning -1 causes operation not permitted. */
  if (to>from){
    textbuffer_copy_to(d->memcache->txtbuf,from,to,buf);
    return to-from;
  }
  return d->memcache->memcache_already<=from && d->memcache->memcache_status==memcache_done?-1:0;
}

/* Invoked from xmp_read, where struct fHandle *d=fhandle_get(path,fd) */
static off_t memcache_wait_and_read(char *buf, const off_t size, const off_t offset,struct fHandle *d,struct fuse_file_info *fi){
  log_entered_function("%s ",D_VP(d));

  const bool ok=memcache_wait(d,offset+size);
  log_debug_now("%s  ok: %d",D_VP(d),ok);
  LOCK_N(mutex_fhandle,const off_t memcache_l=is_memcache(d,NULL)? d->memcache->memcache_l: -1); /* Otherwise md5sum fails with EPERM */
  if (memcache_l<0 || !ok) return -1;
  if (offset==memcache_l) return 0;
  if (memcache_l){
    LOCK_N(mutex_fhandle,const off_t num=memcache_read(buf,d,offset,size+offset));
    if (num>0) COUNTER_INC(COUNT_READZIP_MEMCACHE);
    if (num>0 || memcache_l>=offset) return num;
  }
  return -1;
}

////////////////////////////////////////////////////////////
/// After loading, compare with crc32 stored in ZIP file ///
////////////////////////////////////////////////////////////
static bool fhandle_check_crc32(struct fHandle *d){
  ASSERT_LOCKED_FHANDLE();
  if (!is_memcache(d,NULL) || !d->memcache->txtbuf->n) return false;
  const off_t st_size=d->zpath.stat_vp.st_size;
  const uint32_t crc=cg_crc32(textbuffer_first_segment(d->memcache->txtbuf),st_size,0,_mutex+mutex_crc);
  if (d->zpath.zipcrc32!=crc){
    warning(WARN_MEMCACHE|WARN_FLAG_ERROR,D_VP(d),"crc32-mismatch!  ZIP: %x != computed: %x size=%zu already: %zu  rp=%s",d->zpath.zipcrc32,crc,st_size,d->memcache->memcache_already,D_RP(d));
    return false;
  }
  return true;
}
//////////////////////////////////////////////////////////////////////////////////////
/// When can copying bytes to RAM be interrupted?                                  ///
/// 1. flag FHANDLE_FLAG_DESTROY_LATER must be set                                 ///
/// 2. the fHandle instance is not used.                                           ///
/// 2. No other fHandle process is using the struct memcache instance              ///
//////////////////////////////////////////////////////////////////////////////////////
static bool memcache_store_try(struct fHandle *d, struct async_zipfile *zip, struct rootdata *r){
  //static int count; log_entered_function("%s  #%d",D_VP(d),++count);
  bool contin, ok;
  char rp[PATH_MAX];
  LOCK(mutex_fhandle,  if ((ok=contin=is_memcache(d,r))) strcpy(rp,ZP_RP(&d->memcache->m_zpath)));
  if (!ok) return false;
  const bool isZIP=d->zpath.flags&ZP_ZIP;
  const int fd=isZIP?0:open(rp,O_RDONLY);
  if (isZIP) openzip_now(zip);
  if (!zip->zf && fd<=0){ warning(WARN_MEMCACHE|WARN_FLAG_ERRNO|WARN_FLAG_ERROR,rp,"Failed %s() d=%p",isZIP?"zip_open":"open",d); return false; }
  const off_t st_size=d->zpath.stat_vp.st_size;
  off_t already=0;
  LOCK(mutex_fhandle,if ((ok=contin=is_memcache(d,r))) async_memcache_update_time(d,r));
  char *buf=cg_malloc(COUNT_MEMCACHE_MALLOC,MEMCACHE_READ_BYTES_NUM);
  for(;st_size>already;){
    const off_t n_max=MIN_long(MEMCACHE_READ_BYTES_NUM,st_size-already);
    const off_t n=zip->zf?my_zip_fread(zip->zf,buf,n_max):read(fd,buf,n_max);
    if (n<=0){ ok=false; warning(WARN_MEMCACHE,rp,"n<0  d=%p  read=%'zu st_size=%'ld",d,already,st_size); break;}
    { /* copy bytes */
      lock(mutex_fhandle);
      char *dst=NULL;
      if ((ok=contin=(is_memcache(d,r) && !memcache_can_break(d)))){
        dst=textbuffer_first_segment_with_min_capacity(st_size>SIZE_CUTOFF_MMAP_vs_MALLOC?TXTBUFSGMT_MUNMAP:0,d->memcache->txtbuf,st_size);
        if ((ok=(dst!=NULL))){
          memcpy(dst+already,buf,n);
          if ((already+=n)>d->memcache->memcache_already)  d->memcache->memcache_already=already;
          async_memcache_update_time(d,r);
        }
      }
      unlock(mutex_fhandle);
    }
    if (!ok) break;
  }/*for already*/
  cg_free(COUNT_MEMCACHE_MALLOC,buf);
  const char *msg=NULL;
  if (already!=st_size){ /* Not Completely read */
    if (contin) msg=RED_WARNING" already!=st_size";
  }else if (isZIP){
    LOCK(mutex_fhandle, ok=fhandle_check_crc32(d));
    fhandle_counter_inc(d,ok?ZIP_READ_CACHE_CRC32_SUCCESS:ZIP_READ_CACHE_CRC32_FAIL);
    msg=ok?GREEN_SUCCESS" crc32 OK":RED_WARNING" already==st_size  crc32 wrong";
  }
  if (msg) IF_LOG_FLAG(LOG_MEMCACHE) log_exited_function("%s  %s  st_size: %lld\n",rp,msg,(LLD)st_size);
  if (fd) close(fd); else closezip_now(zip);
  log_exited_function("rp: %s  e: %s ok: %d  contin: %d",rp,D_EP(d),ok,contin);
  return ok;
}
//////////////////////////////////////////////////////////////////////
/// Try NUM_MEMCACHE_STORE_RETRY times to run memcache_store_try() ///
//////////////////////////////////////////////////////////////////////
static void memcache_now(struct fHandle *d, struct rootdata *r){
  cg_thread_assert_not_locked(mutex_fhandle);
  const struct zippath *zpath=&d->zpath;
  log_entered_function("%s",VP());
  _Static_assert(NUM_MEMCACHE_STORE_RETRY>0,"");
  FOR(retry,0,NUM_MEMCACHE_STORE_RETRY){
    struct async_zipfile zip;
    bool ok,contin;
    LOCK(mutex_fhandle, if ((ok=contin=is_memcache(d,r))) async_zipfile_init(&zip,&d->memcache->m_zpath));
    if (!ok) break;
    if (retry){ log_verbose("Going to sleep 1s and retry  %s ...",VP()); usleep(1000*1000);} // cppcheck-suppress knownConditionTrueFalse
    const int64_t start=currentTimeMillis();
    if ((ok=memcache_store_try(d,&zip,r))){
      lock(mutex_fhandle);
      if ((contin=is_memcache(d,r))){
        d->memcache->memcache_took_mseconds=currentTimeMillis()-start;
        if(retry){ // && d->memcache->memcache_already==d->zpath.stat_vp.st_size
          warning(WARN_RETRY,VP(),"Success on retry %d",retry);fhandle_counter_inc(d,COUNT_RETRY_MEMCACHE);
        }
      }
      unlock(mutex_fhandle);
    }
    if (!contin || ok){
      log_exited_function("%s",VP());
      return;
    }
  }/*for retry*/
}
/////////////////////////////////////////////////////////////////////////////////
/// Directly set bytes to struct memcache                                     ///
/// Needed for autogen and for getting the real file path with suffix @SOURCE ///
/////////////////////////////////////////////////////////////////////////////////
static bool fhandle_set_text(struct fHandle *d, struct textbuffer *b){
  ASSERT_LOCKED_FHANDLE();
  struct memcache *m=memcache_new(d);
  if (b==m->txtbuf) return true;
  if(m->txtbuf) return false; /* This can be triggered by special files */
  m->txtbuf=b;
  m->memcache_already=m->memcache_l=textbuffer_length(b);
  d->flags|=FHANDLE_FLAG_MEMCACHE_COMPLETE;
  return true;
}



///////////////
/// Timeout ///
///////////////
static void async_memcache_update_time(struct fHandle *d, struct rootdata *r){
  ASSERT_LOCKED_FHANDLE();
  if (is_memcache(d,r)){
    const time_t t=time(NULL);
    if (r) atomic_store(r->thread_when_success+PTHREAD_MEMCACHE,t);
    else r=d->zpath.root;
    assert(r!=NULL);
    atomic_store(r->async_when+ASYNC_MEMCACHE,t);
  }
}
#if MEMCACHE_TIMEOUT_SECONDS
static time_t memcache_time_exceeded(const struct fHandle *d){
  lock(mutex_fhandle);
  struct rootdata *r=d->zpath.root;
  assert(r!=NULL);
  time_t t=time(NULL)-atomic_load(r->async_when+ASYNC_MEMCACHE);
  unlock(mutex_fhandle);
  return t>MEMCACHE_TIMEOUT_SECONDS;
}
#endif //MEMCACHE_TIMEOUT_SECONDS
/* If memcache_async() has not been run before, start it.  Wait for completion of min_fill. */
static bool memcache_wait(struct fHandle *d, const off_t min_fill){
  cg_thread_assert_not_locked(mutex_fhandle);
  assert(d->is_busy>0);
  assert(d->zpath.root!=NULL);
  {
    lock(mutex_fhandle);
    if (!d->memcache){
      memcache_new(d);
      d->memcache->txtbuf=textbuffer_new(COUNT_MALLOC_MEMCACHE_TXTBUF);
      memcache_set_status(d,memcache_queued);
      async_memcache_update_time(d,NULL);
    }
    unlock(mutex_fhandle);
  }
 again_with_other_root:
  for(int i=0;;i++){
    off_t a,memcache_l;
    enum enum_memcache_status status;
    bool ok;
#define F (a>=min_fill || a>=memcache_l)
    LOCK(mutex_fhandle, ok=is_memcache(d,NULL);  a=!ok?0:d->memcache->memcache_already; memcache_l=!ok?0:d->memcache->memcache_l;status=!ok?0:d->memcache->memcache_status);
    if (!ok || F) return ok;
    if (status!=memcache_reading && status!=memcache_queued) return F;
#undef F
#if MEMCACHE_TIMEOUT_SECONDS
    if (memcache_time_exceeded(d)){
      warning(WARN_MEMCACHE,D_RP(d),"Timeout > "STRINGIZE(MEMCACHE_TIMEOUT_SECONDS)" s");
      COUNTER_INC(COUNT_MEMCACHE_WAITFOR_TIMEOUT);
      struct zippath zp={0};
      LOCK_N(mutex_fhandle, ok=is_memcache(d,NULL); if (ok) zp=d->memcache->m_zpath);
      if (ok && find_realpath_other_root(&zp)){
        lock(mutex_fhandle);
        d->memcache->m_zpath=zp;
        d->memcache->memcache_already=0;
        async_memcache_update_time(d,NULL);
        memcache_set_status(d,memcache_queued);
        unlock(mutex_fhandle);
        goto again_with_other_root;
      }
      return false;
    }
#endif //MEMCACHE_TIMEOUT_SECONDS
    usleep(50+MIN(i,1<<18));
    if (!(i&1023)) fputc(status==memcache_queued?'q':'r',stderr);
  }
  return false;
}

/* Each remote root has its own  infloop_memcache thread. Loading file content into RAM asynchronously. */
static void *infloop_memcache(void *arg){
  struct rootdata *r=arg;
  init_infloop(r,PTHREAD_MEMCACHE);
  /* pthread_cleanup_push(infloop_memcache_start,r); Does not work because pthread_cancel not working when root blocked. */
  for(int i=0;;i++){
    struct fHandle *d=NULL;
    {
      lock(mutex_fhandle);
      foreach_fhandle(id,e){
        if (e->memcache && e->memcache->memcache_status==memcache_queued && e->memcache->m_zpath.root==r) d=e;
      }
      unlock(mutex_fhandle);
    }
    if (d && wait_for_root_timeout(r)){
      LOCK_N(mutex_fhandle,const bool q=(memcache_queued==memcache_get_status(d)));
      if (q){
        LOCK(mutex_fhandle,memcache_set_status(d,memcache_reading); atomic_fetch_add(&d->is_memcache_store,1));
        log_debug_now("%s",D_VP(d));
        memcache_now(d,r);
        LOCK(mutex_fhandle,memcache_set_status(d,memcache_done); atomic_fetch_add(&d->is_memcache_store,-1));
      }
    }
    usleep(100*1000);
  }
}

// COUNT_MALLOC_MEMCACHE_TXTBUF cg_free_null_malloc_id COUNT_S textbuffer   textbuffer_new(COUNT_MALLOC_MEMCACHE_TXTBUF)
